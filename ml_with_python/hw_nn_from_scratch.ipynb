{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G40l9lO2ObLr"
   },
   "source": [
    "## Homework: neural network from scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Two-layer fully connected neural network in numpy\n",
    "\n",
    "This task proposes to implement the simple fully connected neural network “from scratch”, that is, only in numpy.\n",
    "To do this, you need to implement forward pass and backpropagation with updating the weights.\n",
    "\n",
    "It is advisable to do everything without additional loops, and it is imperative to achieve convergence on the binary classification problem four vertices of a two-dimensional square.\n",
    "\n",
    "The result of the work should be an implementation (.py or .ipynb) and a clear report (.ipynb or .pdf) with a brief description of the solution and a chart of the resulting convergence.\n",
    "If possible, run some experiments to speed up convergence by adding regularization or mini-batch learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "import datetime\n",
    "\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def sigmoid_derivative(x):\n",
    "    return x * (1 - x)\n",
    "\n",
    "def print_with_datetime(s):\n",
    "    time_string = datetime.datetime.now().strftime(\"%H:%M:%S\")\n",
    "    sys.stdout.write(\"\\r\" + time_string + \" \" + s)\n",
    "    sys.stdout.flush()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-15T07:00:38.331069500Z",
     "start_time": "2023-09-15T07:00:38.073564900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial hidden weights: [0.70929289 0.50913448] [0.51600901 0.07859918]\n",
      "Initial hidden biases: [0.66660437 0.73506938]\n",
      "Initial output weights: [0.58579294] [0.51092257]\n",
      "Initial output biases: [0.85213546]\n",
      "10:06:50 Epoch 1 Loss 1.0000\n",
      "Final hidden weights: [0.70929289 0.50913448] [0.51600901 0.07859918]\n",
      "Final hidden bias: [0.66660437 0.73506938]\n",
      "Final output weights: [0.58579294] [0.51092257]\n",
      "Final output bias: [0.85213546]\n",
      "\n",
      "Output from neural network after 2 epochs: [0] [0] [0] [0]\n"
     ]
    }
   ],
   "source": [
    "# Input datasets\n",
    "inputs = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "target = np.array([[0], [1], [1], [0]])\n",
    "\n",
    "epochs = 2 # 10000\n",
    "lr = 0.1\n",
    "input_layer_neurons, hidden_layer_neurons, output_layer_neurons = 2, 2, 1\n",
    "\n",
    "# Random weights and bias initialization\n",
    "hidden_weights = np.random.uniform(size=(input_layer_neurons, hidden_layer_neurons))\n",
    "hidden_bias = np.random.uniform(size=(1, hidden_layer_neurons))\n",
    "output_weights = np.random.uniform(size=(hidden_layer_neurons, output_layer_neurons))\n",
    "output_bias = np.random.uniform(size=(1, output_layer_neurons))\n",
    "\n",
    "print(\"Initial hidden weights: \", end='')\n",
    "print(*hidden_weights)\n",
    "print(\"Initial hidden biases: \", end='')\n",
    "print(*hidden_bias)\n",
    "print(\"Initial output weights: \", end='')\n",
    "print(*output_weights)\n",
    "print(\"Initial output biases: \", end='')\n",
    "print(*output_bias)\n",
    "\n",
    "# Training algorithm\n",
    "for epoch in range(epochs):\n",
    "    # Forward Propagation\n",
    "    # hidden_outputs = ...\n",
    "    \n",
    "    # calc predicted_output below \n",
    "    predicted_output = [[0], [0], [0], [0]]\n",
    "\n",
    "    # Loss\n",
    "    loss = 0.5 * (target - predicted_output) ** 2\n",
    "    loss = loss.sum()\n",
    "    print_with_datetime(\"Epoch {} Loss {:.4f}\".format(epoch, loss))\n",
    "\n",
    "    # Backpropagation\n",
    "    # loss_by_output = ...\n",
    "    # predicted_output_derivative = ...\n",
    "\n",
    "    # loss_by_output_bias = ...\n",
    "\n",
    "    # loss_by_output_weights = ...\n",
    "\n",
    "    # loss_by_hidden_outputs = ...\n",
    "\n",
    "    # hidden_outputs_derivative = ...\n",
    "\n",
    "    # loss_by_hidden_weights = ...\n",
    "\n",
    "    # Updating Weights and Biases\n",
    "    # output_bias -= ...\n",
    "    # output_weights -= ...\n",
    "    # hidden_bias -= ...\n",
    "    # hidden_weights -= ...\n",
    "\n",
    "print('')\n",
    "print(\"Final hidden weights: \", end='')\n",
    "print(*hidden_weights)\n",
    "print(\"Final hidden bias: \", end='')\n",
    "print(*hidden_bias)\n",
    "print(\"Final output weights: \", end='')\n",
    "print(*output_weights)\n",
    "print(\"Final output bias: \", end='')\n",
    "print(*output_bias)\n",
    "\n",
    "print(f\"\\nOutput from neural network after {epochs} epochs: \", end='')\n",
    "print(*predicted_output)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-15T07:06:50.949037800Z",
     "start_time": "2023-09-15T07:06:50.918758200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "colab": {
   "name": "Two-layer neural network from scratch",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
