<!doctype html>
<html lang="en">
	<head>
		<meta charset="utf-8">
		<meta name="apple-mobile-web-app-capable" content="yes" />
		<meta name="apple-mobile-web-app-status-bar-style" content="black-translucent" />
		<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">

		<title>Linear models, SGD</title>

		<link rel="stylesheet" href="../dist/reset.css">
		<link rel="stylesheet" href="../dist/reveal.css">
		<link rel="stylesheet" href="../dist/theme/black.css">

        <!-- Theme used for syntax highlighted code -->
		<link rel="stylesheet" href="../plugin/highlight/monokai.css">

		<link rel="stylesheet" href="https://pyscript.net/latest/pyscript.css" />
		<script defer src="https://pyscript.net/latest/pyscript.js"></script>
		<py-config>
			terminal = false
            packages = ["numpy", "matplotlib"]
		</py-config>
    </head>
	<body onload="totalWrapper();">
		<div class="reveal">
			<div class="slides">
                <section>
					<div>
						<img src="images/nup_logo_dark.jpeg" alt="nup_logo" />
					</div>
						<h2>Machine Learning with Python</h2>
					<div class="fragment" style="margin-bottom:20px;">
							<div class="typesetting">
								<h3>Lecture 7. Linear models, Stochastic Gradient Descent</h3>
								<br />
								Alexander Avdiushenko <br />
								October 24, 2023
							</div>
					</div>
                </section>
                <section>
                    <section>
                        <h3>Training Regression as Optimization Task</h3>

                        <div class="fragment" style="margin-bottom:20px;">
                            <div class="typesetting">
                                <p style="text-align: left">Training sample:
                                    $X^\ell = (x_i, y_i)^\ell_{i=1}$, $x_i \in \mathbb{R}^n$,  $y_i \in \mathbb{R}$</p>
                            </div>
                        </div>

                        <div class="fragment" style="margin-bottom:20px;">
                            <div class="typesetting">
                                <p style="text-align: left">Linear regression model (weights $w \in \mathbb{R}^n$):</p>
                                <p>$a(x, w) = \left< w, x\right> = w^T x= \sum\limits_{j=1}^n w_jf_j(x)$</p>
                            </div>
                        </div>

                        <div class="fragment" style="margin-bottom:20px;">
                            <div class="typesetting">
                                <p style="text-align: left">Squared loss function:</p>
                                <p>$\mathcal{L} (a, y) = (a - y)^2$</p>
                            </div>
                        </div>

                        <div class="fragment" style="margin-bottom:20px;">
                            <div class="typesetting">
                                <p style="text-align: left">Training Method — Least Squares Method:</p>
                                <p>$Q(w) = \frac1\ell\sum\limits_{i=1}^\ell (a(x_i, w) - y_i)^2 \to \min\limits_w$</p>
                            </div>
                        </div>

                        <div class="fragment" style="margin-bottom:20px;">
                            <div class="typesetting">
                                <p style="text-align: left">Testing on the test set $X^k = (\tilde{x}_i, \tilde{y}_i)_{i=1}^k$:</p>
                                <p>$\overline{Q}(w) = \frac1k\sum\limits_{i=1}^k (a(\tilde{x}_i, w) - \tilde{y}_i)^2$</p>
                            </div>
                        </div>
                    </section>
                    <section>
                        <h3>Training Classification as Optimization Task</h3>

                        <div class="fragment" style="margin-bottom:20px;">
                            <div class="typesetting">
                                <p style="text-align: left">Training sample:
                                    $X^\ell = (x_i, y_i)^\ell_{i=1}$, $x_i \in \mathbb{R}^n$, $\ \color{orange}{y_i \in \{-1, +1\}}$</p>
                            </div>
                        </div>

                        <div class="fragment" style="margin-bottom:20px;">
                            <div class="typesetting">
                            <p style="text-align: left">Classification Model — Linear (weights $w \in \mathbb{R}^n$):</p>
                            $a(x, w) = {\color{orange}\textrm{sign}} \left< w, x\right> = {\color{orange}\textrm{sign}}(\sum\limits_{j=1}^n w_jf_j(x))$
                            </div>
                        </div>

                        <div class="fragment" style="margin-bottom:20px;">
                            <div class="typesetting">
                                <p style="text-align: left">Loss Function — Binary or its approximation:</p>
                                $\mathcal{L} (a, y) = [ay < 0] = [\left< w, x\right> y < 0] \leq \overline{\mathcal{L}}(\left< w, x\right>, y)$
                            </div>
                        </div>

                        <div class="fragment" style="margin-bottom:20px;">
                            <div class="typesetting">
                                <p style="text-align: left">Training Method — Minimization of Empirical Risk:</p>
                                $Q(w) = \frac1\ell\sum\limits_{i=1}^\ell [\left< w, x_i\right> y_i < 0]
                                \leq \frac1\ell\sum\limits_{i=1}^\ell \overline{\mathcal{L}} (\left< w, x_i\right>, y_i) \to \min\limits_w$
                            </div>
                        </div>

                        <div class="fragment" style="margin-bottom:20px;">
                            <div class="typesetting">
                                <p style="text-align: left">Testing on the test set: $X^k = (\tilde{x}_i, \tilde{y}_i)_{i=1}^k$</p>

                                $\overline{Q}(w) = \frac1k\sum\limits_{i=1}^k \color{orange}{[\left<\tilde{x}_i, w\right> \tilde{y}_i < 0]}$
                            </div>
                        </div>
                    </section>
                    <section>
                        <h3>The Concept of Margin for Separating Classifiers</h3>

                        <div class="fragment" style="margin-bottom:20px;">
                            <div class="typesetting">
                                <p style="text-align: left">Separating classifier:</p>

                                <p>$a(x, w) = \mathrm{sign}\ g(x, w)$</p>

                                <p>$g(x, w)$ — separating (discriminant) function, $g(x, w) = 0$ — equation of the separating surface</p>

                                <p>$M_i(w) = g(x_i, w)y_i$ — margin of object $x_i$</p>

                                <p>$M_i(w) \leq 0 \iff$ algorithm $a(x, w)$ makes a mistake on $x_i$</p>
                            </div>
                        </div>
                    </section>
                    <section>
                        <h3>Continuous Approximations of the Threshold Loss Function $\mathcal{L}(M)$</h3>

                        <p style="text-align: left">$[M<0]$ — threshold loss function
                            (<span style="color: orange">is not continuous!</span>)</p>
                        <p style="text-align: left">$V(M) = (1 − M)_+$ — piecewise linear (SVM)</p>
                        <p style="text-align: left">$H(M) = (−M)_+$ — piecewise linear (Hebb's rule)</p>
                        <p style="text-align: left">$L(M)=\log_2(1 + \exp(-M))$ — logarithmic (LR)</p>
                        <p style="text-align: left">$Q(M)=(1 − M)^2$ — quadratic</p>
                        <p style="text-align: left">$S(M)=2(1+\exp(M))^{-1}$ — sigmoidal</p>
                        <p style="text-align: left">$E(M)= \exp(-M)$ – exponential (remember for AdaBoost)</p>
                    </section>
                    <section data-background-color="#fdf6e3">
                        <py-repl>
                            import matplotlib.pyplot as plt
                            import numpy as np

                            fig, ax = plt.subplots()

                            ax.set_xlabel('M')
                            x = np.linspace(-5.5, 5.5, num=100)
                            acc_loss = x < 0
                            V_M = (1 - x) * ((1 - x) > 0)
                            H_M = acc_loss * (-x)
                            L_M = np.log2(1 + np.exp(-x))
                            Q_M = (1 - x)**2
                            S_M = 2 * (1 + np.exp(x))**(-1)
                            E_M = np.exp(-x)

                            ax.plot(x, acc_loss, 'b', label='[M<0]')
                            ax.plot(x, V_M, 'g', label='V_M')
                            ax.plot(x, H_M, '.g', label='H_M')
                            ax.plot(x, L_M, 'r', label='L_M')
                            ax.plot(x, Q_M, '--c', label='Q_M')
                            ax.plot(x[::5], S_M[::5], '^m', label='S_M')
                            ax.plot(x, E_M, 'k:', label='E_M')

                            ax.set_ylim(-0.5, 5.5), ax.grid(True)
                            fig.set_size_inches(14, 8)
                            plt.legend(loc='best')
                            plt.savefig('loss_functions.png')
                        </py-repl>
                    </section>
                    <section  data-background-color="#ffffff">
                        <img src="images/loss_functions.png" alt="loss_functions" width="100%">
                    </section>
                    <section>
                        <h3>Linear Classifier — Mathematical Model of a Neuron</h3>

                        <p style="text-align: left">Linear model of the McCulloch-Pitts neuron, 1943:</p>
                        <p>$a(x, w) = f(\left< w, x\right>) = f\left(\sum\limits_{j=1}^n w_j x_j - w_0 \right)$</p>

                        <div class="fragment" style="margin-bottom:20px;">
                            <div class="typesetting">
                                <ul>
                                    <li> $f(z)$ — activation function (for example, $\mathrm{sign}$)</li>
                                    <li> $w_j$ — weight coefficients of synaptic connections</li>
                                    <li> $w_0 = b$ — activation threshold or bias</li>
                                    <li> $w, x \in \mathbb{R}^{n+1}$ — if you introduce a constant feature $x_0 \equiv -1$</li>
                                </ul>
                            </div>
                        </div>
                        <img src="images/artificial_neuron.jpg" alt="artificial_neuron">
                    </section>
                </section>
                <section>
                    <section>
                        <h3>Gradient Method of Numerical Minimization</h3>

                        <div class="fragment" style="margin-bottom:20px;">
                            <div class="typesetting">
                            <p style="text-align: left">Minimization of empirical risk (regression, classification):</p>
                            $Q(w) = \frac{1}{\ell} \sum\limits_{i=1}^\ell \mathcal{L}_i(w) \to \min\limits_w$
                            </div>
                        </div>

                        <div class="fragment" style="margin-bottom:20px;">
                            <div class="typesetting">
                            <p style="text-align: left">Numerical minimization by the <b>gradient descent</b> method:</p>
                            <p>$w^{(0)} = $ initial approximation</p>
                            <p>$w^{(t+1)} = w^{(t)} - h \nabla_w Q(w^{(t)})$</p>
                            <p>where $\nabla_w Q(w) = \left(\frac{\partial Q(w)}{\partial w_j} \right)^n_{j=0}$</p>
                            <p>$w^{(t+1)} = w^{(t)} - \frac{h}{l} \sum\limits_{i=1}^\ell \nabla_w \mathcal{L}_i(w^{(t)})$</p>
                            <p style="text-align: left">where $h$ is the gradient step, also known as the <b>learning rate</b></p>
                            </div>
                        </div>

                        <div class="fragment" style="margin-bottom:20px;">
                            <div class="typesetting">
                            <p style="text-align: left">Idea of Speeding up Convergence:
                                take $(x_i, y_i)$ one by one and immediately update the weight vector —
                                stochastic gradient descent.</p>
                            </div>
                        </div>
                    </section>
                    <section data-background-color="#fdf6e3">
                        <h3>Visualization of the Gradient Method</h3>

                        <div class="fragment" style="margin-bottom:20px;">
                            <div class="typesetting">
                                <div align="center">
                                  <img src="images/gradient-trajectory.png" alt="gradient" width="1000"/>
                                    <p>Two possible trajectories of gradient descent:</p>
                                    <p>In version (a), the target function has "good behavior", which allows the point
                                    to smoothly move to the optimum by the gradient</p>
                                    <p>In version (b), the gradient begins to oscillate as it falls into a narrow valley,
                                    thus converging more slowly</p>
                                </div>
                            </div>
                        </div>
                    </section>
                    <section>
                        <h3>Stochastic Gradient Descent</h3>

                        <div class="fragment" style="margin-bottom:20px;">
                            <div class="typesetting">
                                <p><strong>Input</strong>: sample $X^\ell$, learning rate $h$, decay rate $\lambda$</p>
                                <p><strong>Output</strong>: weight vector $w$</p>

                                <ol>
                                    <li>Initialize weights $w_j,\ j = 0, \dots, n$</li>
                                    <li>Initialize the estimate of the functional:
                                        $\overline{Q} = \frac1\ell \sum\limits_{i=1}^\ell \mathcal{L}_i(w)$</li>
                                    <li><strong>Repeat:</strong></li>
                                        <ul>
                                            <li>Select object $x_i$ from $X^\ell$ randomly</li>
                                            <li>Compute the loss: $\varepsilon_i = \mathcal{L}_i(w)$</li>
                                            <li>Make a gradient step: $w = w - h \nabla_w \mathcal{L}_i(w)$</li>
                                            <li>Assess the functional:
                                                $\overline{Q} = \lambda \varepsilon_i + (1 - \lambda) \overline{Q}$</li>
                                        </ul>
                                    <p><strong>Until</strong> the value $\overline{Q}$ and/or weights $w$ converge</p>
                                </ol>

                                <hr/>
                                <p><em>Robbins, H., Monro S.</em> A stochastic approximation method //
                                    Annals of Mathematical Statistics, 1951, 22 (3), p. 400—407.</p>
                            </div>
                        </div>
                    </section>
                    <section>
                        <div class="fragment" style="margin-bottom:20px;">
                            <div class="typesetting">
                                <div class="r-frame">
                                <b>Question 1:</b> Where did the recursive estimate of the error functional come from?
                                $$\overline{Q} := \lambda \varepsilon_i + (1 - \lambda) \overline{Q}$$
                                </div>
                            </div>
                        </div>
                    </section>
                    <section>
                        <h3>Recursive Estimate of Error Functional</h3>

                        <div class="fragment" style="margin-bottom:20px;">
                            <div class="typesetting">
                            <p style="text-align: left"><strong>Problem</strong>: Calculating the $Q$ estimate over the entire selection
                                $x_1, \dots, x_\ell$ is much slower than the gradient step for a single object $x_i$</p>

                            <p style="text-align: left"><strong>Solution</strong>: Use an approximate recursive formula. Arithmetic Mean:</p>

                            <p>$\overline{Q}_m = \frac1m \varepsilon_m + \frac1m \varepsilon_{m-1} + \frac1m \varepsilon_{m-2} + \dots$</p>

                            <p>$\overline{Q}_m = {\color{orange}\frac1m} \varepsilon_m + {\color{orange}\left(1 - \frac1m\right)} \overline{Q}_{m-1}$</p>

                            <p style="text-align: left">Exponential Moving Average:</p>

                            <p> $\overline{Q}_m = \lambda \varepsilon_m + \left(1 - \lambda\right)\lambda\varepsilon_{m-1} + \left(1 - \lambda\right)^2\lambda\varepsilon_{m-2} + \dots$ </p>

                            <p> $\overline{Q}_m = {\color{orange}\lambda} \varepsilon_m + {\color{orange}\left(1 - \lambda\right)} \overline{Q}_{m-1}$ </p>

                            <p>The parameter $\lambda$ is the rate of forgetting the history of the series.</p>
                            </div>
                        </div>
                    </section>
                    <section>
                        <h3>SAG Algorithm (Stochastic Average Gradient)</h3>

                        <div class="fragment" style="margin-bottom:20px;">
                            <div class="typesetting">
                                <p><strong>Input</strong>: sample $X^\ell$, learning rate $h$, decay rate $\lambda$</p>

                                <p><strong>Output</strong>: weight vector $w$</p>

                                <ol>
                                    <li>Initialize weights $w_j,\ j = 0, \dots, n$</li>
                                    <li><span style='color:orange'>Initialize gradients: $G_i = \nabla \mathcal{L}_i(w), i = 1, \dots, \ell$</span></li>
                                    <li>Initialize the estimate of the functional:
                                        $\overline{Q} = \frac1\ell \sum\limits_{i=1}^\ell \mathcal{L}_i(w)$</li>
                                    <li><strong>Repeat</strong></li>
                                    <ul>
                                        <li>Select object $x_i$ from $X^\ell$ randomly</li>
                                        <li>Compute the loss: $\varepsilon_i = \mathcal{L}_i(w)$</li>
                                        <li><span style='color:orange'>Compute the gradient: $G_i = \nabla \mathcal{L}_i(w)$</span></li>
                                        <li>Make a gradient step: $w := w - h {\color{orange} \frac1\ell \sum_{i=1}^\ell G_i}$</li>
                                        <li>Estimate the functional: $\overline{Q} = \lambda \varepsilon_i + (1 - \lambda) \overline{Q}$</li>
                                    </ul>
                                    <p><strong>Until</strong> the value of $\overline{Q}$ and/or weights $w$ converge</p>
                                </ol>
                                <hr />

                                <p><em>Schmidt M., Le Roux N., Bach F.</em> Minimizing finite sums with
                                    the stochastic average gradient // arXiv.org, 2013.</p>
                            </div>
                        </div>
                    </section>
                    <section>
                        <h3>Weight Initialization Variants</h3>

                        <div class="fragment" style="margin-bottom:20px;">
                            <div class="typesetting">
                            <ol>
                                <li>$w_j = 0$ for all $j = 0, \dots, n$</li>
                                <li>Small random values: $$w_j = \text{random}\left(- \frac{1}{2n}, \frac{1}{2n}\right)$$</li>
                                <li>$w_j = \frac{\left< y, f_j \right>}{\left< f_j, f_j \right>}$,
                                    where $f_j = (f_j(x_i))_{i=1}^\ell$ — vector of feature values</li>
                                <p>This estimate of $w$ is optimal if
                                <ul>
                                    <li>The loss function is quadratic, and</li>
                                    <li>The features are uncorrelated: $\left< f_j, f_k \right> = 0, j \neq k$</li>
                                </ul></p>
                                <li>Training on a small random sub-sample of objects</li>
                                <li>Multi-start: multiple starts from different random initial approximations and
                                    choosing the best solution</li>
                            </ol>
                            </div>
                        </div>
                    </section>
                    <section>
                        <h3>Variants of Training Object Order</h3>

                        <div class="fragment" style="margin-bottom:20px;">
                            <div class="typesetting">
                            <ol>
                                <li>Shuffling of objects: alternately take objects from different classes</li>
                                <li>More frequently take objects with larger errors: the smaller margin $M_i$,
                                    the higher the probability to take the object</li>
                                <li>More frequently take objects with lower confidence: the smaller $|M_i|$,
                                    the higher the probability to take the object</li>
                                <li>Do not take "good" objects at all, for those $M_i > \mu_+$
                                    (this can slightly speed up convergence)</li>
                                <li>Do not take outlier objects at all, for those $M_i < \mu_-$
                                    (this can potentially improve classification quality)</li>
                                <p>You will have to adjust the parameters $\mu_+, \mu_-$</p>
                            </ol>
                            </div>
                        </div>
                    </section>
                    <section>
                        <h3>Variants of Gradient Step Selection</h3>

                        <div class="fragment" style="margin-bottom:20px;">
                            <div class="typesetting">
                                <ol>
                                    <li>Convergence is guaranteed (for convex functions) when</li>
                                    <p>$$h_t \to 0, \sum\limits_{t=1}^{\infty} h_t = \infty, \sum\limits_{t=1}^{\infty} h_t^2 < \infty,$$</p>
                                    <p>in particular, you can set $h_t = 1/t$</p>

                                    <li>The method of fastest gradient descent:</li>
                                    <p>$$\mathcal{L}_i(w - h\nabla \mathcal{L}_i(w)) \to \min\limits_h$$</p>
                                    <p>allows you to find an adaptive step $h^*$. For a quadratic loss function, $h^* = \|x_i\|^{-2}$</p>
                                    <li>Test random steps for "knocking out" the iterative process from local minima</li>
                                    <li>The Levenberg-Marquardt method (second order)</li>
                                </ol>
                            </div>
                        </div>
                    </section>
                    <section>
                        <h3>Levenberg-Marquardt Diagonal Method</h3>

                        <div class="fragment" style="margin-bottom:20px;">
                            <div class="typesetting">
                                <p style="text-align: left">Newton-Raphson method, $\mathcal{L}_i(w) \equiv \mathcal{L}(\left< w, x_i\right>y_i)$:</p>
                                <p>$w = w - h(\mathcal{L}_i^{\prime\prime}(w))^{-1} \nabla \mathcal{L}_i(w)$</p>

                                <p style="text-align: left">where
                                    $\mathcal{L}_i^{\prime\prime}(w) = \left( \frac{\partial^2\mathcal{L}_i(w)}{\partial w_j \partial w_k} \right)$
                                    — hessian, an $n\times n$ matrix</p>

                                <p style="text-align: left"><strong>Heuristic</strong>. We assume that the hessian is diagonal:</p>

                                <p>$w_j = w_j - h\left(\frac{\partial^2\mathcal{L}_i(w)}{\partial w_j^2} + \mu\right)^{-1} \frac{\partial \mathcal{L}_i(w)}{\partial w_j}$,</p>

                                <p style="text-align: left">$h$ — learning rate, we can assume $h = 1$</p>
                                <p style="text-align: left">$\mu$ — parameter that prevents zeroing of the determinant</p>

                                <p>The ratio $h/\mu$ is the learning rate on flat parts of the functional $\mathcal{L}_i(w)$,
                                    where the second derivative is zeroed out.</p>
                            </div>
                        </div>
                    </section>
                </section>
                <section>
                    <section>
                        <h3>Overfitting Problem</h3>

                        <div class="fragment" style="margin-bottom:20px;">
                            <div class="typesetting">
                            <p style="text-align: left"><strong>Possible reasons for overfitting</strong>:</p>
                            <ul>
                                <li>Too few objects and too many features</li>
                                <li>Linear dependence (multicollinearity) of features:</li>
                                <ul>
                                    <li>Suppose a classifier has been built: $a(x, w) = \mathrm{sign} \left< w, x\right>$</li>
                                    <li>Multicollinearity: $\exist u \in \mathbb{R}^{n+1}: \forall x_i \in X^\ell \left< u, x_i\right> = 0$</li>
                                    <li>Non-uniqueness of the solution: $\forall \gamma \in \mathbb{R}\ a(x, w) = \mathrm{sign} \left< w + \gamma u, x\right>$</li>
                                </ul>
                            </ul>
                            </div>
                        </div>

                        <div class="fragment" style="margin-bottom:20px;">
                            <div class="typesetting">
                            <p style="text-align: left"><strong>Manifestations of overfitting</strong>:</p>
                            <ul>
                                <li>Too large weights $|w_j|$ of different signs</li>
                                <li>Instability of the discriminant function $\left< w, x\right>$</li>
                                <li>$Q(X^\ell) \lt\lt Q(X^k)$</li>
                            </ul>
                            </div>
                        </div>

                        <div class="fragment" style="margin-bottom:20px;">
                            <div class="typesetting">
                            <p style="text-align: left"><strong>Main way to reduce overfitting</strong>:</p>
                            <p>Regularization (weight decay)</p>
                            </div>
                        </div>
                    </section>
                    <section>
                        <div class="r-frame">
                            <b>Question 2:</b> How to make the model reduce weights?
                        </div>

                        <br/>
                        <div class="fragment" style="margin-bottom:20px;">
                            <div class="typesetting">
                            <h3>Regularization (weight decay)</h3>

                            <p style="text-align: left">Penalty for increasing the norm of the weight vector:</p>

                            <p>$\mathcal{\tilde L}_i(w) = \mathcal{L}_i(w) + \frac{\tau}{2} \|w\|^2 = \mathcal{L}_i(w) +
                            \frac{\tau}{2}\sum\limits_{j=1}^n w_j^2  \to \min\limits_w$</p>

                            <p>Gradient: $\nabla \mathcal{\tilde L}_i(w) = \mathcal{\tilde L}_i(w) + \tau w$</p>

                            <p style="text-align: left">Modification of the gradient step:</p>

                            <p>$w = w{\color{orange}(1 - h\tau)} - h \nabla \mathcal{L}_i(w)$</p>
                            </div>
                        </div>
                        <div class="fragment" style="margin-bottom:20px;">
                            <div class="typesetting">
                                <p style="text-align: left">Methods for selecting the regularization coefficient $\tau$:</p>
                                <ul>
                                    <li>sliding control</li>
                                    <li>stochastic adaptation</li>
                                    <li>two-level Bayesian inference</li>
                                </ul>
                            </div>
                        </div>
                    </section>
                    <section>
                        <h3>SG: advantages and disadvantages</h3>

                        <div class="fragment" style="margin-bottom:20px;">
                            <div class="typesetting">
                            <p style="text-align: left"><strong>Advantages</strong>:</p>
                            <ul>
                                <li>easy to implement</li>
                                <li>easy to generalize to any $g(x, w), \mathcal{L}(a, y)$</li>
                                <li>easy to add regularization</li>
                                <li>possible dynamic (streaming) learning</li>
                                <li>on super-large samples, you can get a decent solution, even without processing all $x_i, y_i$</li>
                                <li>suitable for tasks with large data</li>
                            </ul>

                            <p style="text-align: left"><strong>Disadvantages</strong>:</p>
                            <ul>
                                <li>selection of a complex of heuristics is an art (do not forget about overfitting, getting stuck, divergence)</li>
                            </ul>
                            </div>
                        </div>
                    </section>
                </section>
                <section>
                    <section>
                        <h3>Principle of maximum likelihood</h3>

                        <div class="fragment" style="margin-bottom:20px;">
                            <div class="typesetting">
                                <p>Let $X \times Y$ be a probability space, and the model (i.e., its parameters $w$)
                                    is also generated by some probability distribution.</p>

                                <p style="text-align: left">Bayes' theorem:</p>

                                <p>$P(A|B) = \frac{P(B|A)P(A)}{P(B)}$</p>

                                <p>$A \equiv w$, $B \equiv Y, X\ \Rightarrow$</p>

                                <p>$P(w|Y, X) = \frac{P(Y, X|w)P(w)}{P(Y, X)} = \frac{P(Y | X, w)P(X|w)P(w)}{P(Y | X)P(X)}$</p>
                                <p>$\boxed{P(w|Y,\ X) = \frac{P(Y|w, X)P(w)}{P(Y | X)}}$</p>

                                <p style="text-align: left">Here:</p>

                                <p>$P(w|Y, X)$ — posterior distribution of parameters</p>
                                <p>$P(Y|X, w)$ — likelihood</p>
                                <p>$P(w)$ — prior distribution of parameters</p>
                            </div>
                        </div>
                    </section>
                    <section>
                        $\arg\max\limits_w P(w|X, Y) = \arg\max\limits_w {P(Y|w, X)P(w)}
                        {\color{orange}=} \arg\max\limits_w \prod\limits_{i=1}^\ell {P(y_i|w, x_i)P(w)} = \\
                        \arg\max\limits_w \sum\limits_{i=1}^l \log P(y_i|w, x_i) + \log P(w)$
                    </section>
                    <section>
                        <h3>Connection of likelihood and approximation of empirical risk</h3>

                        <p style="text-align: left">Maximum likelihood</p>
                        <p>
                            $L(w) = \sum\limits_{i=1}^\ell {\color{orange}\log P(y_i|w, x_i)} \to \max\limits_w$
                        </p>

                        <p style="text-align: left">Minimization of the approximated empirical risk</p>
                        <p>
                            $Q(w) = \sum\limits_{i=1}^\ell {\color{orange}\mathcal{L}(y_i, x_i, w)} \to \min\limits_w$
                        </p>

                        <p style="text-align: left">These two principles are equivalent if we set</p>
                        <p>
                            $ -\log P(y_i|w, x_i) =  \mathcal{L}(y_i, x_i, w)$
                        </p>
                        <p>Model $P(y|x,w) \equiv $ Model $g(x,w)$ and $\mathcal{L}(M)$</p>
                    </section>
                    <section>
                        <h3>Probabilistic interpretation of regularization</h3>

                        <p>
                            \(P(y|x, w)\) — probabilistic data model<br>
                            \(P(w; \gamma)\) — prior distribution of model parameters, \(\gamma\) — vector of hyperparameters;<br>
                        </p>
                        <p style="text-align: left">Joint likelihood of data and model</p>
                            \[P(X^\ell, w) = P(X^\ell | w)P(w;\gamma)\]

                        <p style="text-align: left">Maximum a Posteriori Probability (MAP) principle:</p>
                        \[ L(w) = \log P(X^\ell, w) = \sum\limits_{i=1}^\ell \log P(y_i|w, x_i) +
                        \underbrace{\color{orange}{\log P(w; \gamma)}}_{\text{regularizer}} \to \max\limits_w \]
                    </section>
                    <section data-background-color="#fdf6e3">
                        <h3>How else can the logarithm help?</h3>
                        <py-repl>
                            import matplotlib.pyplot as plt
                            from matplotlib import cm, ticker
                            from matplotlib.ticker import LinearLocator
                            from mpl_toolkits.mplot3d import axes3d, Axes3D

                            import numpy as np

                            fig = plt.figure()
                            ax = Axes3D(fig)

                            # Make data
                            x = np.arange(-2, 2, 0.25)
                            y = np.arange(-2, 2, 0.25)
                            X, Y = np.meshgrid(x, y)
                            R = np.sqrt(X**2 + Y**2)
                            Z = R**1.2 / 5

                            # Plot the surface
                            surf = ax.plot_surface(X, Y, Z, cmap=cm.coolwarm,
                                                   linewidth=0, antialiased=False)

                            # Customize the z axis.
                            ax.set_zlim(-3.01, 1.01)
                            ax.zaxis.set_major_locator(LinearLocator(10))
                            # A StrMethodFormatter is used automatically
                            ax.zaxis.set_major_formatter(ticker.StrMethodFormatter("{x:.02f}"))

                            # Add a color bar which maps values to colors.
                            fig.colorbar(surf, shrink=0.5, aspect=5)

                            fig
                        </py-repl>
                    </section>
                    <section>
                        <img src="images/loss_example.png" alt="" style="width:49%; float:left;">
                        <img src="images/logloss_example.png" alt="" style="width:50%; float:left;">
                    </section>
                    <section>
                        <h3>Examples: Gaussian and Laplace priors</h3>
                        <p style="text-align: left">
                            Let the weights \(w_j\) be independent, \(Ew_j = 0\), \(Dw_j = С\)</p>

                        <p style="text-align: left">
                            Gaussian distribution and quadratic (\(L_2\)) regularizer:</p>

                        $$P(w; С) = \frac{1}{(2\pi C)^{n/2}} \exp \left(-\frac{{\|w\|^2_2}}{2C}\right)$$

                        $${\|w\|^2_2 = \sum\limits_{j=1}^n w_j^2}$$

                        $$-\log P(w; С) = \frac{1}{2C}\|w\|^2_2 + const$$
                    </section>
                    <section>
                        <p style="text-align: left">
                            Laplace distribution and absolute (\(L_1\)) regularizer:</p>

                        $$P(w; С) = \frac{1}{(2C)^{n}} \exp \left(-\frac{{\|w\|_1}}{C}\right)$$

                        $${\|w\|_1 = \sum\limits_{j=1}^n |w_j|}$$

                        $$-\log P(w; С) = \frac{1}{C}\|w\|_1 + const$$
                        <p>\(C\) — hyperparameter, \(\tau = \frac{1}{C}\) — regularization coefficient</p>
                    </section>
                    <section>
                        <h3>Binary Logistic Regression</h3>

                        <ul>
                            <li>
                                Linear classification model for two classes \(Y = \{-1, 1\}\):<br>
                                \(a(x) = \mathrm{sign} \left< w, x\right>\),
                                \(x, w ∈ \mathbb{R}^n\), margin \(M = \left< w, x\right>y\)
                            </li>
                            <li>
                                Logarithmic loss function:
                                $$\mathcal{L}(M) = \log(1 + e^{-M})$$
                            </li>
                            <li>
                                Conditional probability model:
                                $$ P(y|x, w) = \sigma(M) = \frac{1}{1 + e^{-M}},$$

                                where \(\sigma(M)\) is the sigmoid function, important property: \(\sigma(M) + \sigma(-M) = 1\)
                            </li>
                            <li>
                                Regularized logistic regression learning problem
                                (minimization of approximated empirical risk):
                                $$Q(w) = \sum\limits_{i=1}^\ell \log(1 + \exp(-\left< w, x_i\right>y_i)) + \frac{\tau}{2}\|w\|^2_2 \to \min\limits_w $$
                            </li>
                        </ul>
                    </section>
                    <section>
                        <h3>Multiclass Logistic Regression</h3>

                        <p style="text-align: left">Linear classifier with an arbitrary number of classes \(|Ү|\):</p>
                        <span style="color: orange;">\(a(x) = \arg\max\limits_{y \in Y} < w_y, x>\), \(x, w_y \in \mathbb{R}^n\)</span>

                        <p style="text-align: left">The probability that the object \(x\) belongs to the class \(y\):</p>
                            \(P(y|x,w) = \frac{\exp< w_y, x>}{\sum\limits_{z \in Y} \exp< w_z, x>} = \underset{y \in Y}{\mathrm{softmax}} < w_y, x>\)

                        <p style="text-align: left">The \(\mathrm{softmax}: \mathbb{R}^Y \to \mathbb{R}^Y\) function converts any vector into
                            a normalized vector of a discrete distribution.</p>

                        <p style="text-align: left">Maximization of likelihood (log-loss) with regularization:</p>
                        \( L(w) = \sum\limits_{i=1}^\ell \log P(y_i|w, x_i) - \frac{\tau}{2} \sum\limits_{y \in Y} \|w_y\|^2 \to \max\limits_w \)
                    </section>
                </section>
                <section>
                    <section>
                        <h3>Summary</h3>
                        <div class="fragment" style="margin-bottom:20px;">
                            <div class="typesetting">
                            <ul>
                                <li>The Stochastic Gradient (SG, SAG) method is suitable for any models and loss functions</li>
                                <li>Well suited for large data learning</li>
                                <li>Approximation of the threshold loss function $\mathcal{L}(M)$ allows the use of gradient optimization</li>
                                <li>Functions $\mathcal{L}(M)$, penalizing for the approximation to the class boundary, increase the gap between classes, thereby improving classification reliability</li>
                                <li>Regularization solves the multicollinearity problem and also reduces overfitting</li>
                                <li>Likelihood maximization and minimization of the empirical risk are different views
                                    on the same optimization problem</li>
                            </ul>
                            </div>
                        </div>
                    </section>
                </section>
            </div>
        </div>
		<script src="../dist/reveal.js"></script>
		<script src="../plugin/notes/notes.js"></script>
		<script src="../plugin/markdown/markdown.js"></script>
		<script src="../plugin/highlight/highlight.js"></script>
		<script src="../plugin/math/math.js"></script>
		<script src="../scripts/utils.js"></script>
		<script>
			// More info about initialization & config:
			// - https://revealjs.com/initialization/
			// - https://revealjs.com/config/
			Reveal.initialize({
				hash: true,
				// The "normal" size of the presentation, aspect ratio will
				// be preserved when the presentation is scaled to fit different
				// resolutions. Can be specified using percentage units.
				width: '100%',
				height: '100%',
				// Factor of the display size that should remain empty around the content
				margin: 0.08,

				// Bounds for smallest/largest possible scale to apply to content
				minScale: 0.2,
				maxScale: 2.0,
				plugins: [ RevealMarkdown, RevealHighlight, RevealNotes, RevealMath.KaTeX ]
			});

			Reveal.addEventListener('fragmentshown', function (event) {
				if (lettersAnimate) {
					[...event.fragment.getElementsByClassName('typesetting')].forEach(element => {
						playAnimation(element);
					});
				}
			});
        </script>
    </body>
</html>