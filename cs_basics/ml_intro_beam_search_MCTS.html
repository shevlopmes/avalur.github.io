<!doctype html>
<html lang="en">
	<head>
		<meta charset="utf-8">
		<meta name="apple-mobile-web-app-capable" content="yes" />
		<meta name="apple-mobile-web-app-status-bar-style" content="black-translucent" />
		<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">

		<title>Machine Learning Intro</title>

		<link rel="stylesheet" href="../dist/reset.css">
		<link rel="stylesheet" href="../dist/reveal.css">
		<link rel="stylesheet" href="../dist/theme/moon.css">

        <!-- Theme used for syntax highlighted code -->
		<link rel="stylesheet" href="../plugin/highlight/monokai.css">

		<link rel="stylesheet" href="https://pyscript.net/latest/pyscript.css" />
		<script defer src="https://pyscript.net/latest/pyscript.js"></script>
		<py-config>
			terminal = false
            packages = ["numpy", "matplotlib", "scikit-learn"]
		</py-config>
		<style>
			.column {
			  float: left;
			  width: 48%;
			  padding: 2px;
			}
			/* Clear floats after image containers */
			.row::after {
			  content: "";
			  clear: both;
			  display: table;
			}
			.important {
				color: orange;
			}
		</style>
    </head>
	<body onload="totalWrapper();">
		<div class="reveal">
			<div class="slides">
                <section>
					<div>
						<img src="images/CU_Logotype_RGB_white_blue_red.png" alt="cub_logo" width="60%"/>
					</div>
						<h2>Advanced Algorithms and Data Structures</h2>
					<div class="fragment" style="margin-bottom:20px;">
							<div class="typesetting">
								<h3>Intro to Machine Learning, Beam Search and Monte-Carlo Tree Search</h3>
								<br />
								Alex Avdiushenko <br />
								October 28, 2024
							</div>
					</div>
                </section>
                <section>
                    <section>
    					<div class="fragment" style="margin-bottom:20px;">
                            <img src="../ml_with_python/images/ml_def_from_chatGPT.png" alt="ml_def_from_chatGPT">
                        </div>
                    </section>
                    <section>
                        <div class="fragment" style="margin-bottom:20px;">
                            <div class="typesetting">
                                <p style="text-align: left">ML is built using the tools of mathematical statistics,
                                numerical methods, mathematical analysis, optimization methods, probability theory,
                                    and various techniques for working with data in digital form.</p>
                                <br />
                            </div>
                        </div>
                        <div class="fragment" style="margin-bottom:20px;">
                            <div class="typesetting">
                                <p class="r-frame important" style="text-align: left;padding-left: 10px">What is it?</p>
                            \[\begin{cases}
                                \frac{\partial \rho}{\partial t} + \frac{\partial(\rho u_{i})}{\partial x_{i}} = 0 \\ \\
                                \frac{\partial (\rho u_{i})}{\partial t} + \frac{\partial[\rho u_{i}u_{j}]}{\partial x_{j}} = -\frac{\partial p}{\partial x_{i}} + \frac{\partial \tau_{ij}}{\partial x_{j}} + \rho f_{i}
                              \end{cases}
                            \]
                            </div>
                        </div>
                    </section>
                    <section>
                        <iframe width="1400" height="650" src="https://www.youtube.com/embed/5028bTvDwO8"></iframe>
                        <div class="fragment" style="margin-bottom:20px;">
                            <div class="typesetting">
                                <p>In machine learning, there is no pre-set model with equations...</p>
                            </div>
                        </div>
                    </section>
                    <section>
                        <h3 style="text-align: left">Types of Machine Learning</h3>
                        <div class="fragment" style="margin-bottom:20px;">
                            <div class="typesetting">
                                <ul>
                                  <li class="fragment"><strong class="important">Supervised Learning:</strong> The algorithm is provided with
                                      <span class="important">labeled</span> training data, and the goal is to learn a general rule
                                      that maps inputs to outputs</li>
                                  <li class="fragment"><strong class="important">Unsupervised Learning:</strong> The algorithm is provided with
                                      <span class="important">unlabeled</span> data and must find the underlying structure in the data,
                                      like clustering or dimensionality reduction</li>
                                  <li class="fragment"><strong class="important">Reinforcement Learning:</strong> The algorithm
                                      <span class="important">learns by interacting</span> with an environment
                                      and receiving feedback in the form of rewards or penalties</li>
                                </ul>
                            </div>
                        </div>
                    </section>
                    <section>
                        <h3>Main notations</h3>

                        <div class="fragment" style="margin-bottom:20px;">
                            <div class="typesetting">
                            <p style="text-align: left">$X$ — set of objects <br>
                            $Y$ — set of answers</p>

                            <p>$y: X \to Y$ — unknown dependence (target function)</p>

                            <p>The task is to find, based on the training sample $\{x_1,\dots,x_\ell\} = X_\ell \subset X$
                                with known answers $y_i=y(x_i)$, <br>
                                an algorithm ${\color{orange}a}: X \to Y$, <br>
                                which is a decision function that approximates $y$ over the entire set $X$</p>
                            </div>
                        </div>
                    </section>
                    <section>
                        <p style="text-align: left">The whole ML course is about this:</p>
                        <ul>
                          <li>how objects $x_i$ are defined and what answers $y_i$ can be</li>
                          <li>in what sense ${\color{orange}a}$ approximates $y$</li>
                          <li>how to construct the function ${\color{orange}a}$</li>
                        </ul>
                    </section>
                    <section>
                            <p>$f_j: X \to D_j$ </p>

                            <p>The vector $(f_1(x), \dots, f_n(x))$ is so called "feature description" of the object $x$</p>

                            <p style="text-align: left">Types of features:</p>
                            <ul>
                              <li>$D_j = \{0, 1\}$ — binary</li>
                              <li>$\#|D_j| < \infty $ — categorical</li>
                              <li>$\#|D_j| < \infty, D_j$ ordered — ordinal</li>
                              <li>$D_j = \mathbb{R}$ — real (quantitative)</li>
                            </ul>

                            <div class="fragment" style="margin-top:20px;">
                                <div class="r-frame" style="color: orange">
                                <b>Question 1:</b> How to convert all features to binary?
                            </div>
                        </div>
                    </section>
                    <section>
                        <p style="text-align: left">Data matrix (objects and features as rows and columns):</p>

                        <p><br />
                            $F = ||f_j(x_i)||_{\ell\times n} = \left[ {\begin{array}{ccc}
                           f_1(x_1) & \dots & f_n(x_1) \\
                             \vdots  & \ddots &   \vdots  \\
                           f_1(x_\ell) & \dots & f_n(x_\ell)
                          \end{array} } \right]$
                        </p><br />

                    </section>
                    <section>
                        <h3>Types of tasks</h3>

                        <h4 style="text-align: left">Classification</h4>
                        <ul>
                          <li>$Y = \{-1, +1\}$ — binary classification</li>
                          <li>$Y = \{1, \dots, M\}$ — multiclass classification</li>
                          <li>$Y = \{0, 1\}^M$ — multiclass with overlapping classes</li>
                        </ul>

                        <h4 style="text-align: left">Regression</h4>
                          <p>$Y = \mathbb{R}\ $ or $\ Y = \mathbb{R}^m$</p>

                        <h4 style="text-align: left">Ranking</h4>
                          $Y$ — finite ordered set
                    </section>
                    <section>
                        <h3>Predictive Model</h3>

                        <p style="text-align: left">A model (predictive model) — a parametric family of functions</p>

                        <p>$A = \{g(x, \theta) | \theta \in \Theta\}$,</p>

                        <p style="text-align: left">where $g: X \times \Theta \to Y$ — a fixed function, $\Theta$ — a set of allowable
                            values of parameter $\theta$</p>

                        <div class="fragment" style="margin-bottom:20px;">
                            <div class="typesetting">
                            <h4 style="text-align: left">Example</h4>

                            <p>Linear model with vector of parameters
                                $\theta = (\theta_1, \dots, \theta_n), \Theta = \mathbb{R}^n$:</p>

                            <p>$g(x, \theta) = \sum\limits_{j=1}^n \theta_jf_j(x)$ — for regression and ranking,
                                $Y = \mathbb{R}$</p>

                            <p>$g(x, \theta) = \mathrm{sign}\left(\sum\limits_{j=1}^n \theta_jf_j(x)\right)$ — for classification,
                                $Y = \{-1, +1\}$</p>
                            </div>
                        </div>
                    </section>
                </section>
                <section id="lin_reg_in_Python">
                    <section data-background-color="#fdf6e3">
                        <h3>Example: Regression Task, Synthetic Data</h3>

                        <p style="text-align: left">$X = Y = \mathbb{R}$, $\ell = 50$ objects</p>

                        <p>$n = 3$ features: $\{1, x, x^2\}$ or $\{1, x, \sin x\}$</p>
                        <py-repl>
                            import matplotlib.pyplot as plt
                            import numpy as np
                            np.random.seed(0)

                            l = 50
                            x = np.linspace(0, 30, num=l)
                            Y = x + 4*np.sin(x) + 3*np.random.randn(l)

                            X1 = np.vstack([np.ones_like(x), x, x**2]).T
                            X2 = np.vstack([np.ones_like(x), x, np.sin(x)]).T
                            print(X1.shape, X2.shape)
                        </py-repl>
                    </section>
                    <section data-background-color="#fdf6e3">
                        <py-repl>
                            fig, ax = plt.subplots()
                            ax.set_xlabel('x'), ax.set_ylabel('Y')
                            ax.plot(x, Y, '.', label='train points')

                            x_plot = np.linspace(0, 30, num=1000)
                            ax.plot(x_plot, x_plot + 4*np.sin(x_plot), label='real')
                            plt.legend(loc='best')
                            fig # plt.show()
                        </py-repl>
                    </section>
                    <section data-background-color="#fdf6e3">
                        <py-repl>
                            from sklearn.linear_model import LinearRegression

                            reg1 = LinearRegression(fit_intercept=False)
                            reg1.fit(X1, Y)

                            reg2 = LinearRegression(fit_intercept=False)
                            reg2.fit(X2, Y)

                            print("Models have been trained.")
                        </py-repl>
                        <div class="fragment important" style="margin-top:20px;">
                            <div class="typesetting">
                                <div class="r-frame">
                                    <b>Question 2:</b> What does an <i>intercept</i> mean?
                                </div>
                            </div>
                        </div>
                    </section>
                    <section data-background-color="#fdf6e3">
                        <py-repl>
                            fig, ax = plt.subplots()
                            ax.set_xlabel('x'), ax.set_ylabel('Y')
                            ax.plot(x, Y, '.', label='train points')

                            x_plot = np.linspace(0, 30, num=1000)
                            X1 = np.vstack([np.ones_like(x_plot), x_plot, x_plot**2]).T
                            X2 = np.vstack([np.ones_like(x_plot), x_plot, np.sin(x_plot)]).T
                            ax.plot(x_plot, reg1.predict(X1), label='{1, x, x^2}', linestyle='dashed')
                            ax.plot(x_plot, reg2.predict(X2), label='{1, x, sin(x)}')
                            plt.legend(loc='best')
                            fig
                        </py-repl>
                    </section>
                </section>
                <section>
                    <section>
                        <h3 style="text-align: left">Training Stage</h3>
                        <p style="text-align: left">The method $\mu$ constructs an algorithm $a = \mu(X_\ell, Y_\ell)$ from the sample
                            $(X_\ell, Y_\ell) = (x_i, y_i)_{i=1}^\ell$</p>

                        <p>$\boxed{
                        \left[ {\begin{array}{ccc}
                           f_1(x_1) & \dots & f_n(x_1) \\
                             \dots  & \dots &   \dots  \\
                           f_1(x_\ell) & \dots & f_n(x_\ell)
                          \end{array} } \right]
                        \xrightarrow{y}
                        \left[ {\begin{array}{c}
                        y_1 \\ \dots \\ y_\ell \end{array} }\right]
                        \thinspace}
                        \xrightarrow{\mu} a$</p>

                        <div class="fragment" style="margin-bottom:20px;">
                            <h3 style="text-align: left">Test Stage</h3>
                            <div class="typesetting">
                                <p>The algorithm $a$ produces answers $a(x_i^\prime)$ for new objects $x_i^\prime$</p>
                            </div>
                        </div>
                    </section>
                    <section>
                        <h3 style="text-align: left">Quality Functionals</h3>

                        <p>$\mathcal{L}(a, x)$ — loss function.
                            The error magnitude of the algorithm $a \in A$ on the object $x \in X$</p>

                        <div class="fragment" style="margin-bottom:20px;">
                            <h4 style="text-align: left">Loss Functions for Classification Tasks:</h4>
                            <ul>
                              <li>$\mathcal{L}(a, x) = [a(x)\neq y(x)]$ — indicator of error</li>
                              <li>Cross entropy is distance between two vectors of probabilities</li>
                            </ul>
                        </div>

                        <div class="fragment" style="margin-bottom:20px;">
                            <h4 style="text-align: left">Loss Functions for Regression Tasks:</h4>
                            <ul>
                              <li>$\mathcal{L}(a, x) = |a(x) - y(x)|$ — absolute error value</li>
                              <li>$\mathcal{L}(a, x) = (a(x) - y(x))^2$ — quadratic error</li>
                            </ul>
                        </div>

                        <div class="fragment" style="margin-bottom:20px;">
                            <p style="text-align: left"><em>Empirical risk</em> —
                                functional quality of the algorithm $a$ on $X^\ell$:</p>

                            <p>$Q(a, X^\ell) = \frac{1}{\ell} \sum\limits_{i=1}^\ell \mathcal{L}(a, x_i)$</p>
                        </div>
                    </section>
                    <section>
                        <h3>Reducing the Learning Task to an Optimization Task</h3>

                        <p style="text-align: left">Method of minimizing empirical risk</p>

                        <p>$\mu(X^\ell) = \arg\min\limits_{a \in A} Q(a, X^\ell)$</p>

                        <div class="fragment" style="margin-bottom:20px;">
                            <h4 style="text-align: left">Example: least squares method</h4>
                            <p style="text-align: left">$Y = \mathbb{R}, \mathcal{L}$ is quadratic:</p>
                            $$\mu(X^\ell) = \arg\min\limits_{\theta} \sum\limits_{i=1}^{\ell} (g(x_i, \theta) - y_i)^2$$
                        </div>
                    </section>
                    <section>
                        <h3 style="text-align: left">Generalization Ability Problem</h3>
                        <div class="fragment" style="margin-bottom:20px;">
                            <div class="typesetting">
                            <ul>
                              <li>Will we find the "law of nature" or will we overfit, i.e.,
                                  adjust the function $g(x_i, \theta)$ to the given points?</li>
                              <li>Will $a = \mu(X^\ell)$ approximate the function $y$ over the entire $X$?</li>
                              <li>Will $Q(a, X^k)$ be small enough on new data — the test set
                                  $X^k = (x_i^\prime, y_i^\prime)_{i=1}^k$, $y_i^\prime = y(x_i)$?</li>
                            </ul>
                            </div>
                        </div>

                        <div class="fragment" style="margin-bottom:20px;">
                            <div class="typesetting">
                            <h3 style="text-align: left">Overfitting — one of the main problems in machine learning</h3>

                            <p>When <strong>test_score >> train_score</strong></p>

                                <ul>
                                  <li>What causes overfitting?
                                    <ul>
                                      <li>Excessive complexity of the parameter space $\Theta$,
                                          extra degrees of freedom in the model $g(x, \theta)$ are "spent"
                                          on overly precise fit to the training sample</li>
                                      <li>Overfitting always occurs when there is optimization of parameters
                                          over a finite (inherently incomplete) sample</li>
                                    </ul>
                                  </li>
                                </ul>
                            </div>
                        </div>
                    </section>
                    <section>
                        <div class="typesetting">
                        <ul>
                              <li>How to detect overfitting?
                                <ul>
                                  <li>Empirically, by splitting the sample into train and test</li>
                                </ul>
                              </li>
                              <li>It's impossible to completely get rid of it. How to minimize?
                                <ul>
                                  <li>Minimize the error on validation (Hold Out, Leave One Out, Cross Validation),
                                      but with care!</li>
                                  <li>Put restrictions on $\theta$ (i.e. regularization)</li>
                                </ul>
                              </li>
                        </ul>
                        </div>
                    </section>
                    <section data-background-color="#ffffff">
                        <img src="../ml_with_python/images/cross-validation.png" alt="cross-val">
                    </section>
                </section>
                <section>
                    <section>
                        <h3 style="text-align: left">What is Beam Search?</h3>
                        <ul>
                            <li class="fragment">
                                An approximate search algorithm commonly used in
                                natural language processing tasks like machine translation and speech recognition</li>
                            <li class="fragment">
                                It is a variation of greedy search that explores multiple paths simultaneously,
                                keeping track of the $k$ most promising paths at each step</li>
                            <li class="fragment">
                                <span class="important">Beam search</span> striking a compromise between the efficiency
                                of <span class="important">greedy search</span> and the optimality of
                                <span class="important">exhaustive search</span>
                            </li>
                        </ul>

                        <a class="fragment" href="href=https://d2l.ai/chapter_recurrent-modern/beam-search.html">
                            <img src="images/d2l_beam_search.png" alt="beam_search"
                                style="border-radius: 5%">
                        </a>
                    </section>
                    <section>
                        <h3 style="text-align: left">2000-s: Monte-Carlo Tree Search</h3>
                        <div class="fragment">
                            <div class="typesetting">
                                <ul>
                                    <li>In the 2000s, Monte Carlo Tree Search (MCTS) algorithms were introduced,
                                    resulting in significant improvements in the performance of Go programs and other games</li>
                                    <li>We launch <em>random simulations</em> from the current position,
                                        observe which branches yield more wins, and then repeat the process</li>
                                </ul>

                                <img src="../advanced_ml/images/MCTS_svg.png" style="border-radius: 5%">
                            </div>
                        </div>
                    </section>
                    <section>
                        <h3 style="text-align: left">Monte Carlo Tree Search — UCB1</h3>
                        <div class="fragment">
                            <div class="typesetting">
                                <p style="text-align: left">The main part of MCTS is the formula for selection of the next node.
                                The UCB1 formula looks like this (the same as in multi-armed bandits):</p>

                                $$ UCB1 = \frac{w_i}{n_i} + c \sqrt{\frac{\ln t}{n_i}} $$
                                <p style="text-align: left">where:</p>
                                <ul>
                                    <li>$w_i$ is the number of wins</li>
                                    <li>$n_i$ is the count of simulations for the node associated with action $i$</li>
                                    <li>$c$ is the parameter, by default $c=\sqrt{2}$</li>
                                    <li>$t = \sum\limits_i n_i$ is the total count of simulations for the parent node</li>
                                </ul>

                                <p style="text-align: left">
                                    The algorithm prefers actions with higher estimated rewards and higher uncertainties.
                                </p>
                            </div>
                        </div>
                    </section>
                </section>
                <section>
                    <section>
                        <h3>Now let's dive into Tetris in Javascript</h3>
                        <ul>
                            <li class="fragment"><a href="https://codeincomplete.com/games/tetris"> And play the game now!</a></li>
                            <li class="fragment"><a href="https://codeincomplete.com/articles/javascript-tetris/">Read more about how it works</a></li>
                        </ul>
                    </section>
                    <section>
                        <h3>Tricky part is dealing with rotation of the 7 tetrominoes</h3>
                        <p style="text-align: left">We encode each position of each piece with 16bit, that is four 4bit numbers:</p>
                        <img src="images/16bit_tetrominoes.png" alt="16bit_tetrominoes" style="border-radius: 5%">
                    </section>
                    <section>
                        <img src="images/pieces_in_code.png" alt="pieces_in_code" style="border-radius: 5%;width: 80%">
                    </section>
                    <section>
                        <p style="text-align: left"><a href="https://github.com/avalur/avalur.github.io/blob/master/cs_basics/javascript-tetris/">
                            It's time to look at the code!
                        </a></p>

                        <div class="fragment">
                            <p style="text-align: left">Assignment</p>
                            <ul>
                                <li>The game is written in vanilla Javascript, so you need to understand the code</li>
                                <li>Improve the current heuristic agent, adding new features and tuning the weights: <span class="important">30 points</span></li>
                                <li>Implement a new agent using Beam Search or MCTS: <span class="important">30 points</span></li>
                                <li>Write a report with the results and conclusions: <span class="important">40 points</span></li>
                            </ul>
                        </div>
                        <br>
                        <p class="fragment" style="text-align: left">Please, try to make your report an interesting story,
                            sequentially implementing the algorithms from the tasks.
                            The clarity of the answers to the questions,
                            the tidiness of the report and code are assessed during the verification.</p>
                        <br>
                        <p class="fragment">Good luck and have fun!</p>
                    </section>
                </section>
            </div>
        </div>
		<script src="../dist/reveal.js"></script>
		<script src="../plugin/notes/notes.js"></script>
		<script src="../plugin/markdown/markdown.js"></script>
		<script src="../plugin/highlight/highlight.js"></script>
		<script src="../plugin/math/math.js"></script>
		<script src="../scripts/utils.js"></script>
		<script>
			// More info about initialization & config:
			// - https://revealjs.com/initialization/
			// - https://revealjs.com/config/
			Reveal.initialize({
				hash: true,
				// The "normal" size of the presentation, aspect ratio will
				// be preserved when the presentation is scaled to fit different
				// resolutions. Can be specified using percentage units.
				width: '100%',
				height: '100%',
				// Factor of the display size that should remain empty around the content
				margin: 0.08,

				// Bounds for smallest/largest possible scale to apply to content
				minScale: 0.2,
				maxScale: 2.0,
				plugins: [ RevealMarkdown, RevealHighlight, RevealNotes, RevealMath.KaTeX ]
			});

			Reveal.addEventListener('fragmentshown', function (event) {
				if (lettersAnimate) {
					[...event.fragment.getElementsByClassName('typesetting')].forEach(element => {
						playAnimation(element);
					});
				}
			});
        </script>
    </body>
</html>